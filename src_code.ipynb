{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 237 Final Project: Logistic Regression\n",
    "\n",
    "In this final assignment of the semester, you will analyze some data from the Wisconsin Breast Cancer Data Set to determine risk factors for Breast cancer. This project is due on Thursday, December 14th at midnight. You may complete the project in teams of 2-3 people (not more) or you may elect to do it by yourself. One member of the team should submit all relevant files (specified at the end of this notebook), and the names of all team members should be on all documents. All members will receive the same grade. This project is worth 5% of your final grade and may not be skipped. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Abdulshaheed Alqunber (asq@bu.edu)\n",
    "#### Anuj Jain (anuj12@bu.edu)\n",
    "#### Karan Mago (kmago@bu.edu)\n",
    "#### Wayne Snyder CS237\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'ignore', 'invalid': 'warn', 'over': 'warn', 'under': 'ignore'}"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from collections import Counter\n",
    "from sklearn import decomposition\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "np.seterr(divide=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./Wisconsin_breast_cancer.csv'"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find(name, path): #Helper method for locating files\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if name in files:\n",
    "            return os.path.join(root, name)\n",
    "path =  find('Wisconsin_breast_cancer.csv', \".\" )\n",
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Overview\n",
    "The American Cancer Society estimates that at the end of this year, 252,710 women will have been diagnosed with a new case of invasive breast cancer.  Since the prognosis of a patient diagnosed with an invasive form of breast cancer improves drastically the earlier the cancer is caught, it is imperative to reexamine current diagnostic methods using the most recent technologies, such as machine learning.    \n",
    "\n",
    "The dataset you will analyze for your paper is the\n",
    " Wisconsin breast cancer data set. The collection contains a list of relevant features computed from a digitized image of a Fine Needle Biopsy (FNA) of a breast cancer growth, in which cells from a suspicious growth in the breast are removed by a needle.  The dataset contains 683 entries, each with 10 features with a class identifier, to distinguish between benign and malignant tumors. \n",
    " \n",
    " Here the term $\\textit{benign}$ refers to a tumor, condition, or growth that is not cancerous and unlikely to metastasize (spread). In particular, benign tumors are localized and slow-growing, meaning they have not spread to other parts of the body and are unlikely to do so in the future. That being said, if a tumor gets large enough, it has the potential to press against blood vessels and nerves which can cause problems. Benign tumors can  usually be removed via surgery. On the other hand, if a tumor has the potential to, or already has spread to other parts of the body, this tumor is said to be $\\textit{malignant}$. This type of tumor possesses an immediate risk as it has the potential to spread to the lymphatic system or circulatory system. If the cancer spreads to other regions of the body, it becomes significantly more difficult to treat as localized surgery will no longer remove all of the dangerous cells. \n",
    " \n",
    " Your job for this project is to  construct a predictive model that takes as input a feature vector of values available  from a FNA and predicts whether or not the patient has cancer. The mathematical model we will use for prediction is called **Logistic Regression**. Don't let the name fool you, this is a mathematical model for classification, a common operation in machine learning.\n",
    " \n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data \n",
    "\n",
    "The data is found in the associated file <code>Wisconsin_breast_cancer.csv</code>, which contains 683 records (each representing an individual) as shown in the next cell. The records have the following numeric fields which represent data collected about each individual. \n",
    "\n",
    "- ID number (not used in the analysis)\n",
    "\n",
    "- <code>Clump Thickness</code>: Benign cells tend to be grouped in mono-layers, while cancerous cells are often grouped in multiple layers. \n",
    "\n",
    "- <code>Uniformity of Cell Size</code> and\n",
    "- <code>Uniformity of Cell Shape</code>: Cancer cells tend to vary in size and shape, and larger tumors may be growing and hence non-benign, so these parameters are valuable in determining whether the cells are cancerous or not.\n",
    "\n",
    "- <code>Marginal Adhesion</code>: Normal cells tend to stick together and cancerous cells tend to lose this ability; hence loss of adhesion is a sign of malignancy. \n",
    "\n",
    "- <code>Single Epithelial Cell Size</code>: This is related to the uniformity mentioned above. Epithelial cells that are significantly enlarged may be malignant. \n",
    "\n",
    "- <code>Bare Nuclei</code>:  This is a term used for nuclei that is not surrounded by cytoplasm (the rest of the cell). These are typically seen in benign tumors. \n",
    "\n",
    "- <code>Bland Chromatin</code>: This describes a uniform \"texture\" of the nucleus seen in benign cells. In cancer cells the chromatin tends to be coarser.\n",
    "\n",
    "- <code>Normal Nucleoli</code>: \n",
    "Nucleoli are small structures seen in the nucleus. In normal cells the nucleolus is usually very small if visible at all. In malignant cells the nucleoli become more prominent and numerous. \n",
    "\n",
    "- <code>Mitoses</code>: Cancerous cells tend to undergo mitosis more rapidly and more frequently than healthy cells.  \n",
    "\n",
    "- <code>Target</code>: The result for this individual: 0.0 for benign, 1.0 for malignant\n",
    "\n",
    "More information about the dataset may be found here : https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/Ashaheedq/Library/Mobile Documents/com~apple~CloudDocs/Fall 2017/CS 237/FinalProject\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Clump Thickness</th>\n",
       "      <th>Uniformity of Cell Size</th>\n",
       "      <th>Uniformity of Cell Shape</th>\n",
       "      <th>Marginal Adhesion</th>\n",
       "      <th>Single Epithelial Cell Size</th>\n",
       "      <th>Bare Nuclei</th>\n",
       "      <th>Bland Chromatin</th>\n",
       "      <th>Normal Nucleoli</th>\n",
       "      <th>Mitoses</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Clump Thickness  Uniformity of Cell Size  Uniformity of Cell Shape  \\\n",
       "0              5.0                      1.0                       1.0   \n",
       "1              5.0                      4.0                       4.0   \n",
       "2              3.0                      1.0                       1.0   \n",
       "3              6.0                      8.0                       8.0   \n",
       "4              4.0                      1.0                       1.0   \n",
       "\n",
       "   Marginal Adhesion  Single Epithelial Cell Size  Bare Nuclei  \\\n",
       "0                1.0                          2.0          1.0   \n",
       "1                5.0                          7.0         10.0   \n",
       "2                1.0                          2.0          2.0   \n",
       "3                1.0                          3.0          4.0   \n",
       "4                3.0                          2.0          1.0   \n",
       "\n",
       "   Bland Chromatin  Normal Nucleoli  Mitoses  Target  \n",
       "0              3.0              1.0      1.0     0.0  \n",
       "1              3.0              2.0      1.0     0.0  \n",
       "2              3.0              1.0      1.0     0.0  \n",
       "3              3.0              7.0      1.0     0.0  \n",
       "4              3.0              1.0      1.0     0.0  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(path, index_col=0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashaheedq/Library/Python/3.5/lib/python/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "features = data.columns.values[:-1]\n",
    "target = data.columns.values[-1]\n",
    "\n",
    "target_map = {\n",
    "    'benign':0,\n",
    "    'malignant':1\n",
    "}\n",
    "\n",
    "X, Y = data[features], data[target]\n",
    "Y = np.reshape(Y, (Y.shape[0],1))\n",
    " \n",
    "X_orig = X.copy()\n",
    "a = np.ones( (X.shape[0] , 1))\n",
    "X['1'] = a\n",
    "# Don't worry about the following warning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "This project will have you will build a logistic regression model to predict whether or not a patient has breast cancer. We will cover this topic thoroughly in lectures this week, and readings/viewings have been posted on the class web page. Our purpose here is to overview the technique for the purposes of the discussion today. You will have plenty of time to flesh out the details this week.\n",
    "\n",
    "Logistic regression is a way of adapting linear regression to a situation where the dependent variable Y (the outcome) has only two values, 0 or 1. Hence, the Y variable will follow a Bernoulli distribution, and what we want as an outcome is the probability that the result is 1 (i.e., that the individual has breast cancer), given the values of the parameters $\\theta$ (similar to the parameters $\\theta_0$ and $\\theta_1$ in linear regression) for the model, and the particular input $x$ (the fields in each record). In technical terms, this means that logistic regression calculates the maximum likelihood (or probability) for the $\\theta$ given the data. We derive the cost function assuming the probability of the outcome given x is described by:\n",
    "\n",
    "$P(\\ y=1 \\; \\vert \\; x \\ ; \\ \\theta \\ ) = h_{\\theta}(x)$ \n",
    "\n",
    "$P(\\ y=0 \\; \\vert \\; x \\ ; \\ \\theta \\ ) = 1 - h_{\\theta}(x)$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the technique of Maximum Likelihood, the values for the parameters in $\\theta$ are calculated to be minimum for a likelihood function, which in this case is given as \n",
    "\n",
    "$$L(\\theta) = \\prod_{i=1}^{m}{h_{\\theta}(x^i)}^{y^{(i)}}(1-h_{\\theta}(x^i))^{1-y^{(i)}}$$\n",
    "\n",
    "Taking the log of both sides gives\n",
    "\n",
    "$$\\log L(\\theta) =\\sum_{i=1}^{m} \\ [ \\ -y^{(i)} \\log(h_\\theta(x^{(i)})) \\ - \\ (1 - y^{(i)})\\log(1-h_\\theta(x^{(i)}))$$\n",
    "\n",
    "The goal of logistic regression is to find the $\\theta$ that minimizes the negative log likelihood (which is equivalent to maximizing the log likelihood  and more convenient). \n",
    "To begin, you should implement the cost function and hypothesis function. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sigmoid Squashing Function \n",
    "\n",
    "In order to use linear regression on a Bernoulli outcome, we must adapt our linear regression techniques to a curve which relates the independent variables $x$ to a dependent variable which is a probability in the range (0,1). This is accomplished using the <i> sigmoid</i> function.  Before you start with the actual cost function, you should understand that the logistic regression hypothesis is defined as:\n",
    "\n",
    "$h_\\theta(x) = g( X \\theta)$\n",
    "for $X \\in \\mathbb{R}^{m \\times n }$ ( $m$ examples, $n$ features) and $\\theta \\in \\mathbb{R}^n$\n",
    "\n",
    "where function g is the sigmoid function. The sigmoid function is defined as:\n",
    "\n",
    "$g(z) = \\dfrac{1}{1+e^{-z}}$\n",
    "\n",
    "Your first step is to implement the sigmoid function. When you are finished, plot the sigmoid function, and  test the function with a scalar, a vector, and a matrix.\n",
    "\n",
    "<b>Note: you should use numpy arrays throughout this project!</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "def g(z):\n",
    "    \"\"\"Sigmoid function\"\"\"\n",
    "    return 1 / (1+ (np.e**(-z)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5\n",
      "0.9933071490757153\n",
      "\n",
      "[[ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.]]\n",
      "[[ 0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5]\n",
      " [ 0.5  0.5  0.5  0.5]]\n",
      "\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 0.73105858]\n",
      " [ 0.73105858]\n",
      " [ 0.73105858]\n",
      " [ 0.73105858]]\n",
      "\n",
      "[[ 1.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n",
      "[[ 0.73105858]\n",
      " [ 0.73105858]\n",
      " [ 0.73105858]\n",
      " [ 0.73105858]]\n",
      "\n",
      "[-1  0  2]\n",
      "[ 0.26894142  0.5         0.88079708]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmQAAAGDCAYAAACFuAwbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114ed5550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test 1\n",
    "s0 = 5\n",
    "z0 = np.zeros((4,4))\n",
    "z1 = np.ones(shape=(4,1))\n",
    "z2 = np.array([-1,0,2])\n",
    "\n",
    "print(\"\\n\"+str(s0))\n",
    "print(g(s0))\n",
    "print(\"\\n\"+str(z0))\n",
    "print(g(z0))\n",
    "print(\"\\n\"+str(z1))\n",
    "print(g(z1))\n",
    "print(\"\\n\"+str(z1))\n",
    "print(g(z1))\n",
    "print(\"\\n\"+str(z2))\n",
    "print(g(z2))\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(np.arange(-10,10.5,.5) ,g( np.arange(-10,10.5,.5)))\n",
    "plt.xlabel('z')\n",
    "plt.ylabel('g(z)')\n",
    "plt.grid(True)\n",
    "plt.title(\"Sigmoid Function\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function\n",
    "\n",
    "\n",
    "Now you will implement the cost function. Complete the code\n",
    "in the functions *h* and *computeCost* below to return the value of the hypothesis function and the cost, respectively. Recall that the cost function in logistic regression is\n",
    "\n",
    "$computeCost(\\theta) \\ = \\ \\frac{1}{m} \\ \\sum_{i=1}^{m} \\ [ \\ -y^{(i)} log(h_\\theta(x^{(i)})) \\ - \\ (1 - y^{(i)})log(1-h_\\theta(x^{(i)})) \\ ]$\n",
    "\n",
    "\n",
    "\n",
    "Once you get this working, extend your code to compute the cost function for regularized logistic\n",
    "regression. The regularized cost function in logistic regression is:\n",
    "\n",
    "$computeCost(\\theta;X;Y;\\lambda) \\ = \\ [ \\ \\frac{1}{m} \\ \\sum_{i=1}^{m} \\ [ \\ -y^{(i)} log(h_\\theta(x^{(i)})) \\ - \\ (1 - y^{(i)})log(1-h_\\theta(x^{(i)})) \\ ] \\ ] \\ + \\frac{\\lambda}{2m} \\sum_{j=2}^{n} \\theta_j^2 $\n",
    "\n",
    "The log here is the natural log. Note that you should not regularize the parameter $\\theta_0$ (Why not? Think about why that would be a bad idea).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def h(theta, X): # Logistic hypothesis function\n",
    "    #return g(np.dot(theta,X))\n",
    "\n",
    "\n",
    "    z = 0\n",
    "    for i in range(len(theta)):\n",
    "        z += X[i]*theta[i]\n",
    "    return g(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def computeCost(theta,X,Y, Lambda = 0.): \n",
    "    \"\"\"\n",
    "    theta is an n-dimensional vector of parameters\n",
    "    X is data matrix\n",
    "    Y is a matrix with m-rows and 1 column of target values\n",
    "    This includes regularization if you set Lambda to not be zero (make sure it is non-negative)\n",
    "    \"\"\" \n",
    "    m = Y.size\n",
    "    X = X.values\n",
    "    Y = np.matrix(Y)\n",
    "\n",
    "    cost = np.sum([(-Y[i][0] * np.log(h(theta, X[i].T)) - (1 - Y[i][0]) * np.log(1 - h(theta,X[i].T))) for i in range(m)]) / (m)\n",
    "    reg = (Lambda / (2*m)) * np.sum([pow(theta,2) for i in range(len(theta))])\n",
    "    \n",
    "    ret  = cost + reg\n",
    "    ret = np.nan_to_num(ret)\n",
    "    if ret == 0:\n",
    "        return 99999999999\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together\n",
    " In this section, you will implement the LogisticRegression class. We give you a skeletal outline below:\n",
    "- Class LogisticRegression Attributes:\n",
    "    - Lambda: regularization Parameter\n",
    "    - theta: parameters for prediction\n",
    "- Class LogisticRegression Functions:\n",
    "    - init (given): Constructor.\n",
    "    - fit(self, X,Y, Lambda) ( given): Calls optimizeRegularizedTheta to find parameters for the model. \n",
    "    - optimizeRegularizedTheta (given): Given X,Y and a method of optimization, it will find the value of theta that minimizes the cot function you coded out. It should print out the training accuracy score. \n",
    "   - predict(self, X): predicts the probabilities for all vectors in X\n",
    "   - predict_class(self, X): predicts the class label for all vectors in X\n",
    "   - score(self,X,Y): returns the accuracy for an input X with true labels Y\n",
    "    \n",
    "- Fit will use optimizeRegularizedTheta to find the optimal collection of parameters. (Either read up on how  scip.optimize.minimize works or implement the optimization yourself (not recommended) )\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A solution\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self):\n",
    "        self.Lambda = 0\n",
    "        self.cost = None\n",
    "        self.poly = None\n",
    "        self.accuracy = 0\n",
    "\n",
    "    def optimizeRegularizedTheta(self,X,Y, opt_meth = 'SLSQP'):\n",
    "        result = optimize.minimize(computeCost, x0=self.theta, args=(X, Y, self.Lambda),  method=opt_meth,\n",
    "                                   options={\"maxiter\":5000, \"disp\":False} )\n",
    "        return np.array(result.x), result.fun\n",
    "    \n",
    "    def fit(self, X, Y, Lambda= None):\n",
    "        self.theta = np.zeros((X.shape[1],1))\n",
    "        if Lambda:\n",
    "            self.Lambda =  Lambda\n",
    "        self.theta, mincost = self.optimizeRegularizedTheta(X,Y)\n",
    "        self.theta = np.reshape(self.theta, (len(self.theta) ,1))\n",
    "        self.score(X,Y)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        X_val = X.values\n",
    "        th = (np.matrix(self.theta))\n",
    "        return [h(X_val[i],self.theta)[0] for i in range (len(X_val))]\n",
    "    \n",
    "    def score(self, X, Y):\n",
    "        total = 0\n",
    "        X = self.predict_class(X)\n",
    "        c = []\n",
    "        \n",
    "        for i in range(len(Y)):\n",
    "            if X[i] == Y[i][0]:\n",
    "                total += 1\n",
    "                c.append('True')\n",
    "            else: c.append('False')\n",
    "                \n",
    "        self.accuracy = total/len(Y)\n",
    "        \n",
    "        print(Counter(c))\n",
    "        print(\"Training Accuracy with Lambda = \"+str(self.Lambda)+\" \"+str(self.accuracy))\n",
    "        \n",
    "        return self.accuracy\n",
    "    \n",
    "    def predict_class(self, X):\n",
    "        X = self.predict(X)\n",
    "        return [np.around(x, decimals=0) for x in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Score on the entire Dataset\n",
    "\n",
    "Fit a model to the entire dataset and score the accuracy.  It should be at least 80% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'True': 662, 'False': 21})\n",
      "Training Accuracy with Lambda = 0 0.9692532942898975\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(X,Y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  5.37771924e-01],\n",
       "       [ -7.21033154e-03],\n",
       "       [  3.20301611e-01],\n",
       "       [  3.32871012e-01],\n",
       "       [  9.24578028e-02],\n",
       "       [  3.83923882e-01],\n",
       "       [  4.52240699e-01],\n",
       "       [  2.12767310e-01],\n",
       "       [  5.25390750e-01],\n",
       "       [ -1.01010821e+01]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Potential Thetas\n",
    "clf.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Feature Transformation\n",
    "The hypothesis for a logistic regression is the data is linearly separable. In our case, it appears that it is not.  \n",
    "One way to  achieve a nonlinear decision boundary is to transform the feature space with a non-linear feature mapping. As a result of this mapping, our vector of  features will  be transformed into a $n'$-dimensional\n",
    "vector. A logistic regression classifier trained on this\n",
    "higher-dimension feature vector will have a more complex\n",
    "decision boundary. While there are many maps we can use, we will use a polynomial feature mapping of degree 2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "X_transformed = poly.fit_transform(X_orig)\n",
    "X_tr = pd.DataFrame(X_transformed)\n",
    "X_tr['intercept'] = a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the accuracy goes up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'True': 671, 'False': 12})\n",
      "Training Accuracy with Lambda = 0 0.9824304538799414\n"
     ]
    }
   ],
   "source": [
    "clf_poly = LogisticRegression()\n",
    "clf_poly.fit(X_tr,Y,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.55192224],\n",
       "       [-0.78197746],\n",
       "       [-0.23715026],\n",
       "       [-0.23714916],\n",
       "       [-0.29431998],\n",
       "       [-0.74873108],\n",
       "       [-0.19158666],\n",
       "       [-0.58157485],\n",
       "       [-0.20441249],\n",
       "       [-0.42369593],\n",
       "       [ 0.08532929],\n",
       "       [-0.02517491],\n",
       "       [ 0.14868892],\n",
       "       [-0.22320241],\n",
       "       [ 0.02620216],\n",
       "       [ 0.12227246],\n",
       "       [-0.02233024],\n",
       "       [-0.1216687 ],\n",
       "       [ 0.31998001],\n",
       "       [ 0.02721483],\n",
       "       [-0.19037483],\n",
       "       [ 0.09347761],\n",
       "       [ 0.1288287 ],\n",
       "       [-0.22908437],\n",
       "       [ 0.22588618],\n",
       "       [ 0.0673479 ],\n",
       "       [ 0.01548615],\n",
       "       [ 0.04590981],\n",
       "       [ 0.05579243],\n",
       "       [ 0.09177291],\n",
       "       [ 0.06507466],\n",
       "       [ 0.05387747],\n",
       "       [-0.025123  ],\n",
       "       [-0.0970486 ],\n",
       "       [ 0.16024733],\n",
       "       [-0.09108817],\n",
       "       [ 0.01149946],\n",
       "       [-0.1027946 ],\n",
       "       [ 0.10668141],\n",
       "       [-0.06866411],\n",
       "       [ 0.02106583],\n",
       "       [-0.06577821],\n",
       "       [ 0.18757959],\n",
       "       [-0.09979592],\n",
       "       [-0.04792632],\n",
       "       [ 0.05414652],\n",
       "       [ 0.15631764],\n",
       "       [ 0.01370002],\n",
       "       [-0.13506787],\n",
       "       [-0.05707565],\n",
       "       [-0.17401793],\n",
       "       [ 0.06675055],\n",
       "       [ 0.19760172],\n",
       "       [-0.15674404],\n",
       "       [ 0.08463735],\n",
       "       [-0.55192224]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_poly.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preventing Overfitting \n",
    "To try to prevent overfitting, you will split your data into 3 pieces: training, testing, and validation. \n",
    "- Train is used to fit the model\n",
    "- Validate is used to find the best hyperparameter $\\lambda$ \n",
    "- Test is used to evaluate the model once we have selected a good hyper parameter\n",
    "Implement train_validate_test_split(X,Y) \n",
    "- takes as input X (potentially feature transformed) and Y\n",
    "- returns train, test, validate (where each one is a dataframe with both features and target. Target should be at key index -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Clump Thickness', 'Uniformity of Cell Size',\n",
       "       'Uniformity of Cell Shape', 'Marginal Adhesion',\n",
       "       'Single Epithelial Cell Size', 'Bare Nuclei', 'Bland Chromatin',\n",
       "       'Normal Nucleoli', 'Mitoses', '1'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hint\n",
    "X.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_validate_test_split(X,Y):\n",
    "    # for reproducability\n",
    "    np.random.seed(1234)\n",
    "    X['Target'] = Y\n",
    "    train, validate, test = None, None, None\n",
    "    train, validate, test= np.split(X.sample(frac=1), [int(.6*len(X)), int(.8*len(X))])\n",
    "    return train, validate, test\n",
    "\n",
    "train, validate, test = train_validate_test_split(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_validate_test_split(X,Y):\n",
    "    # for reproducability\n",
    "    np.random.seed(1234)\n",
    "    X['Target'] = Y\n",
    "    train, validate, test = None, None, None\n",
    "    #train, validate, test= np.split(N.sample(frac=1), [int(.6*len(N)), int(.8*len(N))])\n",
    "    \n",
    "    perm = np.random.permutation(X.index)\n",
    "    m = len(X)\n",
    "    train_end = int(.6 * m)\n",
    "    validate_end = int(.2 * m) + train_end\n",
    "    train = X.iloc[perm[:train_end]]\n",
    "    validate = X.iloc[perm[train_end:validate_end]]\n",
    "    test = X.iloc[perm[validate_end:]]\n",
    "    return train, validate, test\n",
    "    \n",
    "    \n",
    "    #return train, validate, test\n",
    "\n",
    "train, validate, test = train_validate_test_split(X,Y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adopted from: \n",
    "How to Split Data into 3 Sets (Train, Validation and Test)? Pandas - How to Split Data into 3 Sets (Train, Validation and Test)? - Stack Overflow, stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Helper Function\n",
    "def data_to_XY(data):\n",
    "    k  = data.keys()\n",
    "    X, Y = data[k[:-1]], data[k[-1]]\n",
    "    Y = np.reshape(Y, (Y.shape[0],1))\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grid search for $\\lambda$\n",
    "\n",
    "Build a model using your training set for each $\\lambda$ in [0,1,10,100,1000,1e6, 1e9]. Select the model that has the highest validation accuracy. Finally, compute the accuracy on testing set and return the selected model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_lambda(lambda_grid, X,Y):\n",
    "    train, validate, test = train_validate_test_split(X,Y)\n",
    "    trainX, trainY = data_to_XY(train)\n",
    "    validateX, validateY = data_to_XY(validate)\n",
    "    testX, testY = data_to_XY(test)\n",
    "    best_lambda = 0\n",
    "    best_lambda_score = 0\n",
    "    best_clf = None\n",
    "    s = []\n",
    "    \n",
    "    for i in range(len(lambda_grid)):\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(trainX,trainY,lambda_grid[i])\n",
    "        s.append(clf.accuracy)\n",
    "        print('after training')\n",
    "        clf.fit(validateX,validateY,lambda_grid[i])\n",
    "        print('after validating')\n",
    "        if clf.accuracy > best_lambda_score: \n",
    "            best_lambda_score = clf.accuracy\n",
    "            best_lambda = clf.Lambda\n",
    "\n",
    "    print('')\n",
    "    print('DONE WITH FINDING LAMBDA')\n",
    "    print('')\n",
    "    \n",
    "    print('best lambda score: '+ str(best_lambda_score))\n",
    "    clf = LogisticRegression()\n",
    "    clf.fit(trainX,trainY,best_lambda)\n",
    "    #clf.fit(validateX,validateY,best_lambda)\n",
    "    #clf.fit(testX,testY,best_lambda)\n",
    "    best_clf = clf\n",
    "    return best_lambda, best_lambda_score, best_clf  , s, testX,testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashaheedq/Library/Python/3.5/lib/python/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'True': 398, 'False': 11})\n",
      "Training Accuracy with Lambda = 0 0.9731051344743277\n",
      "after training\n",
      "Counter({'True': 135, 'False': 1})\n",
      "Training Accuracy with Lambda = 0 0.9926470588235294\n",
      "after validating\n",
      "Counter({'True': 393, 'False': 16})\n",
      "Training Accuracy with Lambda = 1 0.960880195599022\n",
      "after training\n",
      "Counter({'True': 132, 'False': 4})\n",
      "Training Accuracy with Lambda = 1 0.9705882352941176\n",
      "after validating\n",
      "Counter({'True': 380, 'False': 29})\n",
      "Training Accuracy with Lambda = 10 0.9290953545232273\n",
      "after training\n",
      "Counter({'True': 126, 'False': 10})\n",
      "Training Accuracy with Lambda = 10 0.9264705882352942\n",
      "after validating\n",
      "Counter({'True': 345, 'False': 64})\n",
      "Training Accuracy with Lambda = 100 0.843520782396088\n",
      "after training\n",
      "Counter({'False': 71, 'True': 65})\n",
      "Training Accuracy with Lambda = 100 0.47794117647058826\n",
      "after validating\n",
      "Counter({'False': 262, 'True': 147})\n",
      "Training Accuracy with Lambda = 1000 0.3594132029339853\n",
      "after training\n",
      "Counter({'False': 89, 'True': 47})\n",
      "Training Accuracy with Lambda = 1000 0.34558823529411764\n",
      "after validating\n",
      "Counter({'False': 262, 'True': 147})\n",
      "Training Accuracy with Lambda = 1000000.0 0.3594132029339853\n",
      "after training\n",
      "Counter({'False': 89, 'True': 47})\n",
      "Training Accuracy with Lambda = 1000000.0 0.34558823529411764\n",
      "after validating\n",
      "Counter({'False': 262, 'True': 147})\n",
      "Training Accuracy with Lambda = 1000000000.0 0.3594132029339853\n",
      "after training\n",
      "Counter({'True': 107, 'False': 29})\n",
      "Training Accuracy with Lambda = 1000000000.0 0.7867647058823529\n",
      "after validating\n",
      "\n",
      "DONE WITH FINDING LAMBDA\n",
      "\n",
      "best lambda score: 0.9926470588235294\n",
      "Counter({'True': 398, 'False': 11})\n",
      "Training Accuracy with Lambda = 0 0.9731051344743277\n"
     ]
    }
   ],
   "source": [
    "grid = [0,1,10,100,1000,1e6, 1e9]\n",
    "_,_,clf_n ,sc, textX, textY = find_lambda(grid, X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x114a7f6d8>]"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEOCAYAAABmVAtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4XGd59/Hvrc2SvEiWJXsUyVu8xJFHIYtw9sRJwJYM\nJBS6xC2lLCGFNwmhKZTQl1KatrylZWlLAzQkvCQtJHWBpqbYzk5CIITIJI4tb7GdxVIsW7a8y7a2\nu3/MeDJxZHkkz9HRzPw+1zWX5px55px7ZEs/nec85znm7oiIiADkhV2AiIiMHgoFERFJUCiIiEiC\nQkFERBIUCiIikqBQEBGRBIWCiIgkBBYKZvZdM9tlZutO8rqZ2T+b2RYze9HMzg+qFhERSU2QRwrf\nAxoHeb0JmBN/3Ah8K8BaREQkBYGFgrs/BXQO0uQ64D6P+RVQbmbVQdUjIiKnVhDivmuA7UnLrfF1\nOwZ7U2Vlpc+YMSPAskREss/q1at3u3vVqdqFGQopM7MbiXUxMW3aNJqbm0OuSEQks5jZq6m0C3P0\nURswNWm5Nr7uLdz9LndvcPeGqqpTBp2IiAxTmKGwHPhgfBTSRcB+dx+060hERIIVWPeRmd0PLAQq\nzawV+EugEMDdvw2sAJYAW4Au4MNB1SIiIqkJLBTcfekpXnfgpqD2LyIiQ6crmkVEJEGhICIiCRkx\nJDUdtnYcYuuuQ1SMLWLi2CIqSosoKykkL8/CLk1EZNTImVB4qKWdv1+16U3r8gzKS4uYWFrIxNI3\nwmLi2CIqxsbWHQ+RiaWx18YXFyhIRCRr5UwoLH37NC6fXUVnVzf7urrpPNzN3sPddHZ1s/dwD52H\nu9ne2cWa7fvY29VNT58PuJ38PBswRCaWFsYCJClIYq8VMm5MAWYKEhEZ/XImFCbGf1Gnwt053N0X\nC41EcMSDpKubvV09ieVtuw/R+WoPe7u66esfOEgK843y0jdC4k3hEf9afkKolBblK0hEZMTlTCgM\nhZkxbkwB48YUMLWiNKX3uDsHjvayNxEc3XQe7kk6GomFyL6uHjbvPJRod5Icoagg701HIW/q2iot\npHZiKfW1ZUyZUJzGTy4iuU6hkCZmRllJIWUlhcxgbErv6e93DhztSRyBdB6OHXG8OUhi6za8foDO\nrm72H+nBk4Jk8vgxnFNbRrSmLPF18ngFhYgMj0IhRHl5sW6l8tLUurUA+vqdfV3dvLz7MGvb9rO2\ndT8vtu3nsY27EmERmVBMfW0Z59SUEa0to76mjMpxYwL6FCKSTRQKGSY/z5g0bgyTxo2hYUZFYv2h\nY72sf/0AL7buY11bLCgeWb8z8XpNeQnRmgmcU1tOfU0sKFI9xyIiuUOhkCXGjSlgwcwKFsx8IygO\nHu2h5fUDiaOJta37eKjljaConVjyRtdTTSwsykoLwyhfREYJhUIWG19cyEVnTuKiMycl1u0/0kNL\n/EjiePfTirXtidenVZQmup7qa8qYX1NGWYmCQiRXKBRyTFlJIZfMruSS2ZWJdfu6ulnXdoAX2/ax\ntnU/a7bv46cvvjGL+czKsfGjiTLqa8uYf8YExhcrKESykUJBKC8t4rI5lVw2542g6Dzczdq2/bHz\nE637WP1KJz9Z8zoAZrGgOKfm+KincuafMYGxY/TfSSTT6adYBlQxtogr51Zx5dw37nS3+9CxRJfT\n2rb9/GpbJw++8EZQzKoalziaqK8po+6MCZQW6b+YSCYx95NcPTVKNTQ0uO7RPHrsOng0fjTxxvDY\njoPHgNjcUnMmj09cQ1FfW0Zd9QSKC/NDrlok95jZandvOGU7hYKk284DR2MhER/xtLZtP7sPdQOx\nIbVzJo+LhURNGfXxIbL5mmRQJFAKBRk13J3240FxPCza9tN5OBYUc6eM47ON87h63mTN9yQSkFRD\nQR2+Ejgzo7qshOqyEhbPjwCxoGjbd4Rnt3XyL09s4aP3NrNgZgWfa5rHedMmhlyxSO7SkYKErqev\nnwd+/Rr/9NhL7D7UzZL6CJ9ZPI+ZlanNISUip6buI8k4h4718p2ntvGdn2+ju7ef379wGp+8Zo7m\nbRJJA4WCZKxdB4/yz4+9xP2/3k5xQR43XjGLGy6fqesgRE6DQkEy3taOQ/zDqk2sammnctwYPvWO\nOfze26dSmJ8XdmkiGSfVUAj0p8vMGs1sk5ltMbPbB3h9upk9ZmYvmtnPzKw2yHoks8yqGse3//AC\nfvSJS5hZWcrnH1zH4q8/xap17WTaHzMimSKwUDCzfOBOoAmoA5aaWd0Jzb4C3Ofu5wB3AP8vqHok\nc10wfSLL/vhivvPBBvLyjI//+2p++9vP0PxKZ9iliWSdII8UFgBb3H2bu3cDDwDXndCmDng8/vyJ\nAV4XAWLDWt9ZN4VVt17O372vnta9Xfz2t5/hY/c1s2XXwbDLE8kaQYZCDbA9abk1vi7ZGuB98ee/\nBYw3s0mInERBfh7XL5jGzz59FZ9ZfBbPbN3Doq8/xed+/CI7DxwNuzyRjBf2GbtPA1ea2fPAlUAb\n0HdiIzO70cyazay5o6NjpGuUUaikKJ+brprNk59ZyAcvnsEPV7dy5T88wVce2sTBoz1hlyeSsQIb\nfWRmFwNfdPfF8eXPAbj7gOcNzGwcsNHdBz3ZrNFHMpDX9nTxDw9v4idrXqdibBG3XD2bP7hwOkUF\nYf/dIzI6jIbRR88Bc8xsppkVAdcDy5MbmFmlmR2v4XPAdwOsR7LYtEmlfGPpeSy/+VLmRcbzVz9Z\nzzu+9iQ/WfM6/f0aqSSSqsBCwd17gZuBh4ANwDJ3bzGzO8zs2nizhcAmM9sMTAH+Nqh6JDecU1vO\n92+4kO99+O2UFuVzy/3P895v/oJfbt0ddmkiGUEXr0nW6ut3Hny+ja8+vInX9x9l4VlVfLZxHmdX\nTwi7NJERpyuaReKO9vRx3zOv8C+Pb+HgsV7ed14tty2aS015SdiliYwYhYLICfZ1dfPNn23le798\nBYAPXzKD/7NwNmWlheEWJjICFAoiJ9G27whffXgT//V8GxOKC7npqll88OIZuk2oZLXRMPpIZFSq\nKS/ha797Lj+95XLOnVrOl1Zs5JqvPsmPf9OqkUqS8xQKkrPqzpjAvR9ZwA9uuJCKsUXctmwN7/rG\n0zy5uUMT7knOUihIzrtkdiX/fdOl/PPS8zh0rIc/+u6v+cA9z7K2dX/YpYmMOIWCCJCXZ1z7tjN4\n7LaF/OV76tiw4yDv+Zen+eT9z7O9syvs8kRGjE40iwzgwNEe/vXJrdzz9Mv09TsfuGg6t1w9h4qx\nRWGXJjIsGn0kkgbt+4/yj49uZlnzdsYWFfDxhbP4yKUzKSnSSCXJLAoFkTR6aedBvrxqE49u2MmU\nCWO47Z1zef/5tRTo1qCSITQkVSSN5kwZz91/1MCyP76YM8pL+OyP1tL0Tz/n0fU7NVJJsopCQWQI\nFsys4MefuIRv/cH59PY7N9zXzO/96694/rW9YZcmkhYKBZEhMjOa6qt5+E+u4K/fG2Xb7sP81jd/\nyU0/+A1He95yjyiRjKJQEBmmwvw8/vCi6Tz5mYXcdNUsfvriDv7nxR1hlyVyWhQKIqdp7JgCPr3o\nLGrKS1i1TqEgmU2hIJIGZsbi+RGeemm37hEtGU2hIJImTfURunv7eXzjrrBLERk2hYJImlwwbSKT\nx49h1br2sEsRGTaFgkia5OXFupB+tqmDI90ahSSZSaEgkkZN0QhHevp4crO6kCQzKRRE0mjBzAom\nlhayYq26kCQzKRRE0qggP4/F8yM8vnEXx3rVhSSZR6EgkmaN0QiHjvXy9Eu7wy5FZMgCDQUzazSz\nTWa2xcxuH+D1aWb2hJk9b2YvmtmSIOsRGQmXzKpkfHEBKzUKSTJQYKFgZvnAnUATUAcsNbO6E5p9\nHljm7ucB1wPfDKoekZFSVJDHO+um8Mj6nfT09YddjsiQBHmksADY4u7b3L0beAC47oQ2DkyIPy8D\nXg+wHpER0xStZv+RHp7ZuifsUkSGJMhQqAG2Jy23xtcl+yLwATNrBVYAtwRYj8iIuXxOJWOL8tWF\nJBkn7BPNS4HvuXstsAT4NzN7S01mdqOZNZtZc0dHx4gXKTJUxYX5XDVvMg+3tNPXr5vwSOYIMhTa\ngKlJy7Xxdck+CiwDcPdngGKg8sQNuftd7t7g7g1VVVUBlSuSXkvqq9lzuJtfv9wZdikiKQsyFJ4D\n5pjZTDMrInYiefkJbV4DrgEws7OJhYIOBSQrLDyriuLCPE2nLRklsFBw917gZuAhYAOxUUYtZnaH\nmV0bb/anwMfMbA1wP/Ah1w1vJUuUFhVw5dwqVrW0068uJMkQBUFu3N1XEDuBnLzuC0nP1wOXBlmD\nSJiW1FfzUMtOnt++lwumV4RdjsgphX2iWSSrXT1vMkX5eazUXEiSIRQKIgEaX1zIZXMqWbmuHfWM\nSiZQKIgErDEaoW3fEda27Q+7FJFTUiiIBGxR3RQK8kwXsklGUCiIBKy8tIiLZ01ilbqQJAMoFERG\nQGM0wsu7D7Np58GwSxEZlEJBZAQsqotghu7IJqOeQkFkBFSNH8OCGRW6ullGPYWCyAhpikbYvPMQ\nW3YdCrsUkZNSKIiMkMZoNYCOFmRUUyiIjJBIWTHnTyvX0FQZ1RQKIiOoKVpNy+sHeG1PV9iliAxI\noSAyghqjEQBWtagLSUYnhYLICJpaUUq0ZoKGpsqopVAQGWFN0Wpe2L6PHfuPhF2KyFsoFERGWNPx\nLiSdcJZRSKEgMsLOrBrHWVPGaxSSjEqnDAUzu8XMJo5EMSK5oqk+wnOvdLLr4NGwSxF5k1SOFKYA\nz5nZMjNrNDMLuiiRbNcUrcYdHm7ZGXYpIm9yylBw988Dc4B7gA8BL5nZl8xsVsC1iWStuVPGcWbl\nWJ1XkFEnpXMKHpsEvj3+6AUmAj80s78PsDaRrGVmNEYjPLNtD3sPd4ddjkhCKucUbjWz1cDfA78A\n6t39E8AFwPsDrk8kay2pr6av33lkvbqQZPRI5UihAnifuy929/909x4Ad+8H3h1odSJZbP4ZE6id\nWMJKTZAno0gqobAS6Dy+YGYTzOxCAHffEFRhItnOzGiKRnh6y24OHO0JuxwRILVQ+BaQPAH8ofi6\nU4qPVtpkZlvM7PYBXv+6mb0Qf2w2s32plS2SHRqj1fT0OY9tUBeSjA6phIJ50t3G491GBad8k1k+\ncCfQBNQBS82sLrmNu/+Ju5/r7ucC3wB+PJTiRTLdeVPLiUwoZqXmQpJRIpVQ2GZmnzSzwvjjVmBb\nCu9bAGxx923u3g08AFw3SPulwP0pbFcka+TlxUYhPbm5g8PHesMuRySlUPg4cAnQBrQCFwI3pvC+\nGmB70nJrfN1bmNl0YCbw+Elev9HMms2suaOjI4Vdi2SOxmiEY739PLFpV9iliKR08doud7/e3Se7\n+xR3/313T/f/3uuBH7p730lquMvdG9y9oaqqKs27FgnX22dUUDmuSHMhyaiQyrmBYuCjwHyg+Ph6\nd//IKd7aBkxNWq6NrxvI9cBNp6pFJBvl5xmL5kd48Pk2jvb0UVyYH3ZJksNS6T76NyACLAaeJPbL\n/WAK73sOmGNmM82siNgv/uUnNjKzecSukH4m1aJFsk1TNEJXdx9PbVb3qIQrlVCY7e5/ARx293uB\ndxE7rzAod+8FbgYeAjYAy9y9xczuMLNrk5peDzyQPMJJJNdcdOYkykoK1YUkoTtl9xFw/KqafWYW\nJTb/0eRUNu7uK4AVJ6z7wgnLX0xlWyLZrDA/j0V1U1jV0k53bz9FBbrViYQjlf95d8Xvp/B5Yt0/\n64EvB1qVSA5qqo9w8Ggvv9i6O+xSJIcNeqRgZnnAAXffCzwFnDkiVYnkoEtnVzJ+TAGr1rZz1Vkp\nHYyLpN2gRwrxq5f/bIRqEclpYwryuebsyTy8vp3evv6wy5EclUr30aNm9mkzm2pmFccfgVcmkoMa\no9Xs7erh2Zc7T91YJACpnGj+vfjX5OsIHHUliaTdlXOrKCnMZ+W6HVw6uzLsciQHpXJF88wBHgoE\nkQCUFOVz1bwqVq3bSV+/RmnLyEvliuYPDrTe3e9Lfzki0hStZsXadla/upcFM9VTKyMrle6jtyc9\nLwauAX4DKBREAnDVvMkUFeSxct0OhYKMuFOGgrvfkrxsZuXEpsEWkQCMG1PAFXOqWLWunb94Vx15\neRZ2SZJDhnPZ5GFi01yLSECaohF27D/KmlbdjFBGVirnFH5CbLQRxEKkDlgWZFEiue4dZ0+hMN9Y\nta6d86ZNDLscySGpnFP4StLzXuBVd28NqB4RAcpKC7lkViUr17Vze9M8zNSFJCMjle6j14Bn3f1J\nd/8FsMfMZgRalYjQFI3wWmcXLa8fCLsUySGphMJ/AsnX3PfF14lIgBbNj5CfF+tCEhkpqYRCgbt3\nH1+IPy8KriQRAagYW8SFMytYuW5H2KVIDkklFDqSb4pjZtcBmttXZAQ0RSNs7TjMSztTudmhyOlL\nJRQ+Dvy5mb1mZq8BnwX+ONiyRARg8fwIZrBirbqQZGSkMvfRVne/iNhQ1Dp3v8TdtwRfmohMnlBM\nw/SJ6kKSEXPKUDCzL5lZubsfcvdDZjbRzP5mJIoTkdh02hvbD/LK7sNhlyI5IJXuoyZ3T1xWGb8L\n25LgShKRZI3RCAArNQpJRkAqoZBvZmOOL5hZCTBmkPYikkY15SW8rbZMXUgyIlIJhe8Dj5nZR83s\nBuAR4N5gyxKRZE311bzYup/WvV1hlyJZLpUTzV8G/gY4GzgLeAiYHnBdIpKkKd6FpAvZJGipzpK6\nk9ikeL8DXA1sSOVNZtZoZpvMbIuZ3X6SNr9rZuvNrMXMfpBiPSI5ZfqksZxdPUHnFSRwJ50Qz8zm\nAkvjj93AfwDm7lelsmEzywfuBN4JtALPmdlyd1+f1GYO8DngUnffa2aTh/1JRLLckmiErz6ymZ0H\njjJlQnHY5UiWGuxIYSOxo4J3u/tl7v4NYvMepWoBsMXdt8WnxngAuO6ENh8D7oyPaMLddw1h+yI5\npak+1oX0UIuOFiQ4g4XC+4AdwBNm9h0zuwYYyvy9NcD2pOXW+Lpkc4G5ZvYLM/uVmTUOYfsiOWX2\n5PHMnjyOlbq6WQJ00lBw9wfd/XpgHvAE8Clgspl9y8wWpWn/BcAcYCGxbqrvxG/3+SZmdqOZNZtZ\nc0dHR5p2LZJ5mqIRnn15D3sOHQu7FMlSqYw+OuzuP3D39wC1wPPE5j86lTZgatJybXxdslZgubv3\nuPvLwGZiIXFiDXe5e4O7N1RVVaWwa5Hs1BStpt/h4fU7wy5FstSQ7tHs7nvjv6CvSaH5c8AcM5tp\nZkXA9cDyE9o8SOwoATOrJNadtG0oNYnkkrOrxzN9UqlGIUlghhQKQ+HuvcDNxK5r2AAsc/cWM7sj\naSruh4jdyW09sS6qz7j7nqBqEsl0ZkZjNMIvt+xmf1dP2OVIFgosFADcfYW7z3X3We7+t/F1X3D3\n5fHn7u63uXudu9e7+wNB1iOSDZZEq+ntdx7ZoC4kSb9AQ0FE0u+c2jJqyktYpbmQJAAKBZEMY2Ys\nnh/hqZd2c/CoupAkvRQKIhmoqT5Cd28/j2/U9Z6SXgoFkQx0wbSJTB4/RhPkSdopFEQyUF5erAvp\nZ5s66OruDbscySIKBZEM1RSNcKSnjyc36Sp/SR+FgkiGWjCzgomlhbqQTdJKoSCSoQry81g8P8Lj\nG3dxrHcoExiLnJxCQSSDNUYjHDrWy9Mv7Q67FMkSCgWRDHbJrErGFxewQtNpS5ooFEQyWFFBHu+s\nm8KjG3bS09cfdjmSBRQKIhmuKVrN/iM9PLNVc0nK6VMoiGS4y+dUMrYoX6OQJC0UCiIZrrgwn6vm\nTebhlnb6+j3sciTDKRREssCS+mr2HO7m1y93hl2KZDiFgkgWWHhWFcWFeZpOW06bQkEkC5QWFXDl\n3CpWrmunX11IchoUCiJZYkl9NbsOHuP57XvDLkUymEJBJEtcPW8yRfl5rNSFbHIaFAoiWWJ8cSGX\nzalk5bp23NWFJMOjUBDJIo3RCG37jrC2bX/YpUiGUiiIZJFFdVMoyDNdyCbDplAQySLlpUVcPGsS\nK9fuUBeSDEugoWBmjWa2ycy2mNntA7z+ITPrMLMX4o8bgqxHJBc0RiO8sqeLje0Hwy5FMlBgoWBm\n+cCdQBNQByw1s7oBmv6Hu58bf9wdVD0iuWJRXQQz1IUkwxLkkcICYIu7b3P3buAB4LoA9yciQNX4\nMSyYUaGrm2VYggyFGmB70nJrfN2J3m9mL5rZD81saoD1iOSMpmiEzTsPsWXXobBLkQwT9onmnwAz\n3P0c4BHg3oEamdmNZtZsZs0dHR0jWqBIJmqMVgPoaEGGLMhQaAOS//Kvja9LcPc97n4svng3cMFA\nG3L3u9y9wd0bqqqqAilWJJtEyoo5f1q5zivIkAUZCs8Bc8xsppkVAdcDy5MbmFl10uK1wIYA6xHJ\nKU3RalpeP8Bre7rCLkUySGCh4O69wM3AQ8R+2S9z9xYzu8PMro03+6SZtZjZGuCTwIeCqkck1zRG\nIwCsalEXkqTOMu0Cl4aGBm9ubg67DJGM8O5v/JyCvDwevOnSsEuRkJnZandvOFW7sE80i0iAmqLV\nvLB9Hzv2Hwm7FMkQCgWRLNZ0vAtJJ5wlRQoFkSx2ZtU4zpoyXvdYkJQpFESyXFN9hOde7WTXwaNh\nlyIZQKEgkuWaotW4w8MtO8MuRTKAQkEky82dMo4zK8fqvIKkRKEgkuXMjMZohGe27WHv4e6wy5FR\nTqEgkgOW1FfT1+88sl5dSDI4hYJIDph/xgRqJ5awUhPkySkoFERygJnRFI3w9Jbd7D/SE3Y5Moop\nFERyRGO0mp4+5/GN6kKSk1MoiOSI86aWE5lQrAvZZFAKBZEckZcXG4X05OYODh/rDbscGaUUCiI5\npDEa4VhvP09s2hV2KTJKKRREcsjbZ1RQOa5Id2STk1IoiOSQ/Dxj0fwIT2zcxdGevrDLkVFIoSCS\nY5qiEbq6+3hqc0fYpcgopFAQyTEXnTmJspJCdSHJgBQKIjmmMD+PRXVTeHTDTrp7+8MuR0YZhYJI\nDmqqj3DwaC+/2Lo77FJklFEoiOSgS2dXMn5MASvXai4keTOFgkgOGlOQzzVnT+aR9Tvp7VMXkrxB\noSCSoxqj1ezt6uHZlzvDLkVGkUBDwcwazWyTmW0xs9sHafd+M3MzawiyHhF5w5VzqygpzNd02vIm\ngYWCmeUDdwJNQB2w1MzqBmg3HrgVeDaoWkTkrUqK8rlqXhWr1u2kr9/DLkdGiSCPFBYAW9x9m7t3\nAw8A1w3Q7q+BLwNHA6xFRAbQFK1m96FjrH51b9ilyCgRZCjUANuTllvj6xLM7Hxgqrv/NMA6ROQk\nrpo3maKCPHUhSUJoJ5rNLA/4GvCnKbS90cyazay5o0OX5ouky7gxBVwxp4pV69rpVxeSEGwotAFT\nk5Zr4+uOGw9EgZ+Z2SvARcDygU42u/td7t7g7g1VVVUBliySe5qiEXbsP8qa1n1hlyKjQJCh8Bww\nx8xmmlkRcD2w/PiL7r7f3SvdfYa7zwB+BVzr7s0B1iQiJ3jH2VMozDdWaS4kIcBQcPde4GbgIWAD\nsMzdW8zsDjO7Nqj9isjQlJUWcsmsSlaua8ddXUi5LtBzCu6+wt3nuvssd//b+LovuPvyAdou1FGC\nSDiaohFe6+yi5fUDYZciIdMVzSLCovkR8vPUhSQKBREBKsYWceHMClas26EupBynUBARINaFtK3j\nMC/tOhR2KRIihYKIALB4fgQzWLlWXUi5TKEgIgBMnlBMw/SJuro5xykURCShMVrNxvaDvLz7cNil\nSEgUCiKS0BiNAOhoIYcVhF2AiIweNeUlvG1qOff98lU2tR8Muxw5we9cMJXL5lQGug+Fgoi8yQ2X\nzeRrj2xmzXbNhTTaXD1vcuD7UCiIyJu8521n8J63nRF2GRISnVMQEZEEhYKIiCQoFEREJEGhICIi\nCQoFERFJUCiIiEiCQkFERBIUCiIikmCZdkMNM+sAXh3m2yuB3WksJ0z6LKNPtnwO0GcZrU7ns0x3\n96pTNcq4UDgdZtbs7g1h15EO+iyjT7Z8DtBnGa1G4rOo+0hERBIUCiIikpBroXBX2AWkkT7L6JMt\nnwP0WUarwD9LTp1TEBGRweXakYKIiAwiZ0LBzBrNbJOZbTGz28OuZ7jM7LtmtsvM1oVdy+kws6lm\n9oSZrTezFjO7NeyahsvMis3s12a2Jv5Z/irsmk6XmeWb2fNm9j9h13I6zOwVM1trZi+YWXPY9QyX\nmZWb2Q/NbKOZbTCziwPbVy50H5lZPrAZeCfQCjwHLHX39aEWNgxmdgVwCLjP3aNh1zNcZlYNVLv7\nb8xsPLAaeG+G/psYMNbdD5lZIfA0cKu7/yrk0obNzG4DGoAJ7v7usOsZLjN7BWhw94y+TsHM7gV+\n7u53m1kRUOrugdwaL1eOFBYAW9x9m7t3Aw8A14Vc07C4+1NAZ9h1nC533+Huv4k/PwhsAGrCrWp4\nPOZQfLEw/sjYv7bMrBZ4F3B32LUImFkZcAVwD4C7dwcVCJA7oVADbE9abiVDfwFlIzObAZwHPBtu\nJcMX7255AdgFPOLuGftZgH8E/gzoD7uQNHDgYTNbbWY3hl3MMM0EOoD/H+/Su9vMxga1s1wJBRml\nzGwc8CPgU+5+IOx6hsvd+9z9XKAWWGBmGdm1Z2bvBna5++qwa0mTy9z9fKAJuCne/ZppCoDzgW+5\n+3nAYSCw86K5EgptwNSk5dr4OglRvP/9R8D33f3HYdeTDvHD+ieAxrBrGaZLgWvjffEPAFeb2b+H\nW9LwuXtb/Osu4L+IdSVnmlagNeno84fEQiIQuRIKzwFzzGxm/CTN9cDykGvKafGTs/cAG9z9a2HX\nczrMrMrMyuPPS4gNaNgYblXD4+6fc/dad59B7OfkcXf/QMhlDYuZjY0PYiDe3bIIyLhRe+7eDmw3\ns7Piq64BAhuQURDUhkcTd+81s5uBh4B84Lvu3hJyWcNiZvcDC4FKM2sF/tLd7wm3qmG5FPhDYG28\nLx7gz92mTauGAAADnElEQVR9RYg1DVc1cG98lFsesMzdM3ooZ5aYAvxX7O8PCoAfuPuqcEsatluA\n78f/qN0GfDioHeXEkFQREUlNrnQfiYhIChQKIiKSoFAQEZEEhYKIiCQoFEREJEGhICIiCQoFERFJ\nUCgIAGZWb2avmtknTmMbM8zsSNLFaEO+j8VQ7hcxWNuh7Hc42wlr+0F+P+PthzRv/3Du72Fmt5rZ\nuvi9Jz4VX1cSv+dBt5lVprotCYC766EH7g5wMfDMIK9/jNiUIc1Jj+VJr88A1iUt5wNbgTOBImAN\nUHeKGq4gNq/LuhTqHbDtUPc71O2Etf2gv5/x9vcCN8SfFwHlad5+lNhUE6XErjJ+FJid9PorQGXY\nPwu5/NCRgiTbBcwf6AUz+1NiU1Nc7e4NSY9rB9nekO9j4UO4X8QgbYe032FsJ6ztp+37GZ8H7L/N\nrNlid407azjz9g9l+/GXzgaedfcud+8FngTeN9g+ZGQpFCTZ3wFjzGx68sr4nD6/D3zUYzfESVVY\n97FI135Ptp2wtp+W/cZnp70buM3dG4AvEpuKOS3z9g+yfYgdJVxuZpPMrBRYwptnMJaQ5cSEeHJq\nZtYEjAV+Suxo4dWkl6uA2cDq+ORiyV539yUjUqSky3uJ/Rv/KGmyuJ/zxrz9t7j7s2b2T8R+mf9F\nmraPu28wsy8DDxO7L8ALQN/pfiBJH4WCYGbFwJeBa4nNvhgFkmcr7SB2j+uL3H0oP8Bh3cciXfs9\n2XbC2n669vs24P/6CbPrmlmEt87bP5ybuQy4/ePi6++J7/NLxI54ZJRQ95EAfB64z91fAdYSC4WE\neBA8ANx9fH76FA16Hwsze8zMUur+GErbwfabpu2Etf10fT93AIvNLC/+vnozMz/FvP2nu/2k7UyO\nf51G7HzCD1LYpoyUsM906xHuAziL2L2RC5KWf3OStkMafRRft4TYUcZWYn89Hl+fR6yLquSE9vcT\n+6XSQ+wvyI8Ope1g+03XdsLafhq/nyXEjgI2Eeu++fek9ufG/11fBB4EJqZz+/H3/JxY2KwBrjnh\ntVfQ6KNQH7qfgqSNmc0A/sfdT3l/Yovdw/gj7n5bOtuOxHbC2n6Y+x6pz2ax24A2uPvuIPcjJ6dQ\nkLQxs6nAL4E9HruJvUhKLHYb02eIDWqod/eUhiVL+ikUREQkQSeaRUQkQaEgIiIJCgUREUlQKIiI\nSIJCQUREEhQKIiKSoFAQEZEEhYKIiCT8L4wFr7lSSQsMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114a7fd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('$\\lambda \\in [0,1,10,100,1000,1e6, 1e9]$')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot([i for i in range(len(grid))], sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Ashaheedq/Library/Python/3.5/lib/python/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'True': 406, 'False': 3})\n",
      "Training Accuracy with Lambda = 0 0.9926650366748166\n",
      "after training\n",
      "Counter({'True': 136})\n",
      "Training Accuracy with Lambda = 0 1.0\n",
      "after validating\n",
      "Counter({'True': 401, 'False': 8})\n",
      "Training Accuracy with Lambda = 1 0.980440097799511\n",
      "after training\n",
      "Counter({'True': 135, 'False': 1})\n",
      "Training Accuracy with Lambda = 1 0.9926470588235294\n",
      "after validating\n",
      "Counter({'True': 396, 'False': 13})\n",
      "Training Accuracy with Lambda = 10 0.9682151589242054\n",
      "after training\n",
      "Counter({'True': 133, 'False': 3})\n",
      "Training Accuracy with Lambda = 10 0.9779411764705882\n",
      "after validating\n",
      "Counter({'True': 384, 'False': 25})\n",
      "Training Accuracy with Lambda = 100 0.9388753056234719\n",
      "after training\n",
      "Counter({'True': 126, 'False': 10})\n",
      "Training Accuracy with Lambda = 100 0.9264705882352942\n",
      "after validating\n",
      "Counter({'True': 318, 'False': 91})\n",
      "Training Accuracy with Lambda = 1000 0.7775061124694377\n",
      "after training\n",
      "Counter({'False': 88, 'True': 48})\n",
      "Training Accuracy with Lambda = 1000 0.35294117647058826\n",
      "after validating\n",
      "Counter({'False': 262, 'True': 147})\n",
      "Training Accuracy with Lambda = 1000000.0 0.3594132029339853\n",
      "after training\n",
      "Counter({'False': 89, 'True': 47})\n",
      "Training Accuracy with Lambda = 1000000.0 0.34558823529411764\n",
      "after validating\n",
      "Counter({'False': 262, 'True': 147})\n",
      "Training Accuracy with Lambda = 1000000000.0 0.3594132029339853\n",
      "after training\n",
      "Counter({'False': 89, 'True': 47})\n",
      "Training Accuracy with Lambda = 1000000000.0 0.34558823529411764\n",
      "after validating\n",
      "\n",
      "DONE WITH FINDING LAMBDA\n",
      "\n",
      "best lambda score: 1.0\n",
      "Counter({'True': 406, 'False': 3})\n",
      "Training Accuracy with Lambda = 0 0.9926650366748166\n"
     ]
    }
   ],
   "source": [
    "grid = [0,1,10,100,1000,1e6, 1e9]\n",
    "_,_ , model, sct, testXtr, testYtr, = find_lambda(grid, X_tr,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x115cc8630>]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEOCAYAAABmVAtTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115d94710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.xlabel('$\\lambda \\in [0,1,10,100,1000,1e6, 1e9]$')\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.plot([i for i in range(len(grid))], sct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.59528619],\n",
       "       [-0.84053528],\n",
       "       [-0.30994908],\n",
       "       [-0.34059029],\n",
       "       [-0.44855281],\n",
       "       [-0.79235309],\n",
       "       [-0.40409492],\n",
       "       [-0.72281374],\n",
       "       [-0.22450754],\n",
       "       [-0.43283633],\n",
       "       [ 0.22381757],\n",
       "       [ 0.05276797],\n",
       "       [ 0.23183789],\n",
       "       [-0.4821596 ],\n",
       "       [ 0.16775696],\n",
       "       [ 0.19550172],\n",
       "       [-0.19719441],\n",
       "       [-0.38995943],\n",
       "       [ 0.25945622],\n",
       "       [ 0.01058596],\n",
       "       [-0.14906783],\n",
       "       [ 0.20473374],\n",
       "       [ 0.15774878],\n",
       "       [-0.24425662],\n",
       "       [ 0.25936975],\n",
       "       [-0.05055938],\n",
       "       [ 0.04311232],\n",
       "       [-0.01852816],\n",
       "       [-0.07614815],\n",
       "       [-0.25369721],\n",
       "       [ 0.03601176],\n",
       "       [ 0.13419351],\n",
       "       [ 0.1076448 ],\n",
       "       [-0.10456223],\n",
       "       [ 0.2101057 ],\n",
       "       [-0.0489343 ],\n",
       "       [ 0.14076908],\n",
       "       [-0.07775505],\n",
       "       [ 0.13857539],\n",
       "       [-0.15028236],\n",
       "       [ 0.13481169],\n",
       "       [-0.11038207],\n",
       "       [ 0.12312882],\n",
       "       [-0.12136867],\n",
       "       [ 0.05836732],\n",
       "       [ 0.07446991],\n",
       "       [ 0.06513613],\n",
       "       [ 0.09506488],\n",
       "       [-0.16447642],\n",
       "       [ 0.04752161],\n",
       "       [-0.18858339],\n",
       "       [ 0.09476645],\n",
       "       [ 0.326637  ],\n",
       "       [-0.03897697],\n",
       "       [-0.00576192],\n",
       "       [-0.59528619]])"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further exploration\n",
    "Now you should explore how well your model performs with respect to more than just accuracy. Build the confusion matrix and report your model's sensitivity, (true positive rate), specificity (false positive rate), false negative rate, true negative and precision. Interpret your results in each case (IE, how does this metric translate to a real world decision?)\n",
    "For more on the confusion matrix, see https://en.wikipedia.org/wiki/Confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[90,  3],\n",
       "       [ 7, 38]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = model.predict_class(testXtr)\n",
    "cm = confusion_matrix(testYtr, y_preds)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0.0: 93, 1.0: 45})"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(testYtr.flatten()) # Bias in testing set, more examples of clean then there are exaples of cancer!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90 3 7 38\n",
      "accuracy:  0.927536231884\n",
      "sensitivity: 0.844444444444\n",
      "specificity:  0.967741935484\n",
      "precision:  0.926829268293\n"
     ]
    }
   ],
   "source": [
    "def classification_summary(cm):\n",
    "    # 2 class confusion matrix\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    accuracy = (tp+tn) / (tn+fp+fn+tp)\n",
    "    sensitivity = tp/(tp+fn)\n",
    "    specificity = tn/(tn+fp)\n",
    "    precision = tp/(tp+fp)\n",
    "    print(tn,fp,fn,tp)\n",
    "    print('accuracy: ',accuracy)\n",
    "    print('sensitivity:' , sensitivity) #<-- this is a problem! Can you tihnk of how to fix it?\n",
    "    print('specificity: ', specificity)\n",
    "    print('precision: ', precision)\n",
    "classification_summary(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Requirements \n",
    "Select your final model. Reflect on your choice. Did you use a feature transformation? Analyze your results. You must submit your project as a Jupyter notebook containing all your code, and also a Word, Latex, or other document containing your analysis (in English). (You may also do this in a markdown cell at the end of your notebook.)  Your analysis should tell a story...\n",
    "\n",
    "1. Title/abstract: Give your report a title and write a brief (e.g., 100-200 words)\n",
    "abstract summarizing the goal, execution, and conclusions of your project.\n",
    "2. Introduction: An initial section serving as both a start to the paper and an\n",
    "overview\n",
    "3. Background: Here you should summarize the basic prediction problem you face,\n",
    "the nature of the data and the goal(s) of your work.\n",
    "4. Modeling and Analysis: Describe (concisely!) the key steps you took and the\n",
    "findings you obtained in the modeling and analysis of your data. These might include,\n",
    "for example, descriptive analysis through visualizations and summary statistics,\n",
    "transformation of variables suggested by such analysis, initial model building,\n",
    "diagnostic analysis, and further key steps in the iterative process of building your\n",
    "final model. For each key step and/or result, you should include a snippet of the\n",
    "relevant  code in an appendix to your report.\n",
    "Please note: You are not being asked here to simply list everything you tried in\n",
    "analyzing the data! It is up to you to decide what is important and should be\n",
    "included.You will be graded on the soundness of your judgment, as it is reflected\n",
    "in the content and focus of this section.\n",
    "5. Prediction: Shifting to the main goal of this exercise, you should have a separate\n",
    "section describing how you did in predicting the variable of interest. \n",
    "6. Discussion: Use this section to revisit your goals, reflect on the extent to which you\n",
    "feel you achieved them, how the analysis and/or the initial study (i.e,. in which\n",
    "the data were obtained) could be modified the next time, and, ultimately, the\n",
    "implications of your work on. For example, how could a physician leverage your model to make more informed decisions? \n",
    "7. Appendix: Here I wish to see the main snippets of  code you used in doing\n",
    "your analyses. These should be illustrative. So, for example, you should not include\n",
    "every call to plot that you made. But if you include a plot(s) in your main\n",
    "text, then Id like to see the code for that in the appendix. You should include all of the code you used to build the model. **You are only allowed to use a Logistic Regression Model that you implemented yourself! This means you cannot use any package that fully implements Logistic Regression.  **\n",
    "\n",
    "Your total report should be 2-4 pages long. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
